services:
  # VNC Server (Ubuntu)
  remote-desktop:
    image: nishanb/ck-x-simulator-remote-desktop:latest
    build:
      context: ./remote-desktop
    hostname: terminal
    expose:
      - '5901' # VNC port (internal only)
      - '6901' # Web VNC port (internal only)
    environment:
      - VNC_PW=bakku-the-wizard
      - VNC_PASSWORD=bakku-the-wizard
      - VNC_VIEW_ONLY=false
      - VNC_RESOLUTION=1280x800
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:6901/']
      interval: 10s
      timeout: 5s
      retries: 3
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - ckx-network

  # Web Application (not directly exposed to users)
  webapp:
    image: nishanb/ck-x-simulator-webapp:latest
    build:
      context: ./app
    expose:
      - '3000' # Only exposed to internal network
    environment:
      - VNC_SERVICE_HOST=remote-desktop
      - VNC_SERVICE_PORT=6901
      - VNC_PASSWORD=bakku-the-wizard
      - SSH_HOST=remote-terminal
      - SSH_PORT=22
      - SSH_USER=candidate
      - SSH_PASSWORD=password
      - JWT_SECRET=${JWT_SECRET:-ckx-jwt-secret-change-in-production}
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    healthcheck:
      test: ['CMD', 'wget', '-q', '-O', '-', 'http://localhost:3000/']
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - ckx-network

  # Nginx Reverse Proxy - ONLY SERVICE EXPOSED TO USERS
  nginx:
    image: nishanb/ck-x-simulator-nginx:latest
    build:
      context: ./nginx
    depends_on:
      - webapp
      - remote-desktop
      - remote-terminal
      - facilitator
      - sailor-client
      - k8s-api-server
    ports:
      - '30080:80' # Expose Nginx on port 30080
    deploy:
      resources:
        limits:
          cpus: '0.2'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost/']
      interval: 10s
      timeout: 5s
      retries: 3
    networks:
      - ckx-network

  # Jump Host (ckad9999 and ckad9988)
  jumphost:
    image: nishanb/ck-x-simulator-jumphost:latest
    build:
      context: ./jumphost
    hostname: ckad9999
    privileged: true
    # No external port mappings - only accessible internally
    expose:
      - '22' # SSH port (internal only)
    volumes:
      - kube-config:/home/candidate/.kube # Shared volume for Kubernetes config
    deploy:
      resources:
        limits:
          cpus: '1'
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - ckx-network
    healthcheck:
      test: ['CMD', 'nc', '-z', 'localhost', '22']
      interval: 10s
      timeout: 5s
      retries: 3

  # Remote Terminal Service
  remote-terminal:
    image: nishanb/ck-x-simulator-remote-terminal:latest
    build:
      context: ./remote-terminal
    hostname: remote-terminal
    expose:
      - '22' # SSH port (internal only)
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    networks:
      - ckx-network
    healthcheck:
      test: ['CMD', 'nc', '-z', 'localhost', '22']
      interval: 10s
      timeout: 5s
      retries: 3

  # KIND Kubernetes Cluster
  k8s-api-server: # Service name that will be used for DNS resolution
    image: nishanb/ck-x-simulator-cluster:latest
    build:
      context: ./kind-cluster
    container_name: kind-cluster
    hostname: k8s-api-server
    privileged: true # Required for running containers inside KIND
    expose:
      - '6443'
      - '22'
    volumes:
      - kube-config:/home/candidate/.kube # Shared volume for Kubernetes config
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G
    networks:
      - ckx-network
    healthcheck:
      test: ['CMD', 'ls', '/ready']
      interval: 30s
      timeout: 5s
      retries: 20
      start_period: 60s

  # Redis Database for Facilitator
  redis:
    image: redis:alpine
    hostname: redis
    command: ['redis-server', '--appendonly', 'yes']
    expose:
      - '6379'
    restart: unless-stopped
    networks:
      - ckx-network
    deploy:
      resources:
        limits:
          cpus: '0.3'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 5s
      retries: 3

  # PostgreSQL Database for User Authentication
  postgres:
    image: postgres:15-alpine
    hostname: postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-ckx}
      POSTGRES_USER: ${POSTGRES_USER:-ckx}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-ckx-dev-password}
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./facilitator/migrations:/docker-entrypoint-initdb.d:ro
    expose:
      - '5432'
    restart: unless-stopped
    networks:
      - ckx-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U ${POSTGRES_USER:-ckx}']
      interval: 10s
      timeout: 5s
      retries: 5

  # Sailor-Client (Control Plane)
  sailor-client:
    build:
      context: ./sailor-client
      dockerfile: Dockerfile
    hostname: sailor-client
    volumes:
      # Mount facilitator assets so Sailor-Client can read labs.json
      - ./facilitator/assets:/app/facilitator/assets:ro
    ports:
      - '4001:4000' # Expose for local development
    expose:
      - '4000'
    environment:
      - PORT=4000
      - NODE_ENV=prod
      # PostgreSQL Configuration (shared with facilitator)
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-ckx}
      - POSTGRES_USER=${POSTGRES_USER:-ckx}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ckx-dev-password}
      # JWT Configuration
      - JWT_SECRET=${JWT_SECRET:-ckx-jwt-secret-change-in-production}
      - JWT_ACCESS_EXPIRY=15m
      - JWT_REFRESH_EXPIRY=7d
      - BCRYPT_ROUNDS=12
      # CKX Execution Engine (internal APIs)
      - CKX_URL=http://facilitator:3000
      - CKX_SERVICE_SECRET=${SAILOR_CLIENT_SECRET:-change-me-in-production}
      # Stripe Payment Configuration
      - STRIPE_SECRET_KEY=sk_test_51SknIFK4C8jOyCJwb0zidigdDwTKxWMx7wDlDlmdgbkwsdbzX2HkXp8W6KX2Vtq94zBqGk6kjTbpBLpQmvq3fs1W00PgK3O5di
      - STRIPE_PUBLISHABLE_KEY=pk_test_51SknIFK4C8jOyCJwoWDcL78m3LGYVrjcPnOr6yGQtDiG4B0xmibdX9wJ3Tj2QgcrWZl3ilLROdEDRumhaaIgZfh700HXUuPsxl
      - STRIPE_WEBHOOK_SECRET=whsec_338e054c19cddacf9595e8098557021197a6921e8fa1966dfa66f2e9c09a91e4
      - APP_URL=${APP_URL:-http://localhost:30080}
      - LOG_LEVEL=info
    restart: unless-stopped
    depends_on:
      - postgres
      - facilitator
    networks:
      - ckx-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    healthcheck:
      test: ['CMD', 'wget', '-q', '-O', '-', 'http://localhost:4000/health']
      interval: 10s
      timeout: 5s
      retries: 3

  # Facilitator Service (CKX Execution Engine)
  facilitator:
    image: nishanb/ck-x-simulator-facilitator:latest
    build:
      context: ./facilitator
      dockerfile: Dockerfile
    hostname: facilitator
    ports:
      - '3001:3000' # Expose so local webapp (npm run dev) can use FACILITATOR_URL=http://localhost:3001
    expose:
      - '3000'
    environment:
      - PORT=3000
      - NODE_ENV=prod
      - SSH_HOST=jumphost
      - SSH_PORT=22
      - SSH_USERNAME=candidate
      - SSH_PASSWORD= # Empty password for jumphost which allows passwordless auth
      - LOG_LEVEL=info
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - TRACK_METRICS=true # based on the environment variable TRACK_METRICS, the facilitator will send metrics to the metric server
      # Runtime isolation: Always spawn per-user containers for authenticated users (strict isolation)
      # Set SESSION_MODE=ISOLATED to enable (default SHARED for backward compat, but authenticated users always get isolated containers)
      - SESSION_MODE=${SESSION_MODE:-SHARED}
      - DOCKER_NETWORK=ckx-network
      - DOCKER_SOCKET=/var/run/docker.sock
      # Service authentication (for Sailor-Client â†’ CKX internal APIs)
      - SAILOR_CLIENT_SECRET=${SAILOR_CLIENT_SECRET:-change-me-in-production}
      - SERVICE_SECRET=${SAILOR_CLIENT_SECRET:-change-me-in-production}
      # PostgreSQL Configuration
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=${POSTGRES_DB:-ckx}
      - POSTGRES_USER=${POSTGRES_USER:-ckx}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-ckx-dev-password}
      # JWT Configuration
      - JWT_SECRET=${JWT_SECRET:-ckx-jwt-secret-change-in-production}
      - JWT_ACCESS_EXPIRY=15m
      - JWT_REFRESH_EXPIRY=7d
      - BCRYPT_ROUNDS=12
      # Stripe Payment Configuration (Phase 4)
      - STRIPE_SECRET_KEY=sk_test_51SknIFK4C8jOyCJwb0zidigdDwTKxWMx7wDlDlmdgbkwsdbzX2HkXp8W6KX2Vtq94zBqGk6kjTbpBLpQmvq3fs1W00PgK3O5di
      - STRIPE_PUBLISHABLE_KEY=pk_test_51SknIFK4C8jOyCJwoWDcL78m3LGYVrjcPnOr6yGQtDiG4B0xmibdX9wJ3Tj2QgcrWZl3ilLROdEDRumhaaIgZfh700HXUuPsxl
      - STRIPE_WEBHOOK_SECRET=whsec_338e054c19cddacf9595e8098557021197a6921e8fa1966dfa66f2e9c09a91e4
      - APP_URL=${APP_URL:-http://localhost:30080}
    volumes:
      # Docker socket required for strict isolation (spawning per-user containers)
      # Note: Container needs docker group access (GID 995 on this system)
      - /var/run/docker.sock:/var/run/docker.sock:ro
    # Run with docker group GID to access Docker socket
    # Format: GID:UID (docker group:nodeuser)
    # Get docker GID with: getent group docker | cut -d: -f3
    # On this system: docker GID is 995, nodeuser UID is 1001
    # Run with docker group GID (995) as primary group for socket access
    # Format: GID:UID (docker group:nodeuser)
    user: '0:0'
    restart: unless-stopped
    depends_on:
      - jumphost
      - redis
      - postgres
    networks:
      - ckx-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.2'
          memory: 256M
    healthcheck:
      test: ['CMD', 'wget', '-q', '-O', '-', 'http://localhost:3000']
      interval: 10s
      timeout: 5s
      retries: 3

networks:
  ckx-network:
    name: ckx-network
    driver: bridge

volumes:
  kube-config: # Shared volume for Kubernetes configuration
  postgres_data: # Persistent storage for PostgreSQL
